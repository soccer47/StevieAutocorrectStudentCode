Name: Stevie K. Halprin

| Date     |      Time       |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Update |
|:---------|:---------------:|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|
| March 5  |   7pm-7:40pm    |                                                                                                                                                                                                                               I thought for a while on how I would approach this problem set. As of right now I think I'll make 3 recursive methods, one for delete, one for swap, and one for add. I can then run them all on each other, with the base cases for all of them being hitting the threshold or finding a word in the dictionary. |
| March 6  |   7:45pm-8pm    |                         I spent a bit of time trying to implement my recursive approach above and realized that it would be pretty complicated to use the 3 recursive methods while also making my approach time and especially space efficient. I then thought about using a tree or TST instead (like for the problem set where we had to check if it existed in a dictionary or not). I think that I'll have to spend more time thinking about my approach, as this is starting to seem like a much more conceptually intricate problem set. |
| March 8  |  12pm-12:45pm   |                                                                          I spent some more time thinking about how I wanted to approach the problem set, and realized that I may as well start the quasi-recursive approach and see how it goes. I started implementing this approach and have almost finished my methods for delete, swap, and add, with each returning an ArrayList of letters that work with a threshold of 1. I will likely run them multiple times in the main method to get all possible variations of the original word. |
| March 8  | 12:45pm-1:30pm  |                                                                                                                                                                                           I finished the methods for swap, delete, and add, and also have almost finished a first draft of my main method, where I run each method on all of the possible words found so far. I store all of these words as keys in a Hashmap, with the value being the number of edits it took to get to that word. I run [threshold] rounds of these checks.3 |
| March 8  |   3pm-3:40pm    |                  I finished my first draft and tried running my code using the tester files, however I quickly realized that the time complexity of my code was pretty bad. I tried running my code on the smallest test and it didn't finish, leading me to try to add in more break points to reduce unneeded operations, however I still haven't seen my code finish yet. I'll continue to try to make improvements to reduce time consumption, however I also might have to consider a different approach if the situation doesn't improve. |
| March 8  |  6:35pm-7:20pm  |                                                                                                                                                            I spent more time trying to make my code more time efficient, however I still take a very long time on even the small test case, and don't actually return the right top recommended word. I also thought about instead approaching the problem by potentially checking how many edits it would take to get to each word in the dictionary, however I don't know if that would work. |
| March 8  |  7:20pm-7:50pm  |                                                                                                                                                                                          I've started trying to implement a more mathematical approach by going through each word in the dictionary and seeing how many edits away each is from the typed word. I have a feeling that this will actually be a lot faster as it doesn't require me to go through a lot of unnecessary options. I've almost completed a first draft of this code. |
| March 8  |  7:50pm-8:15pm  |                                                                                  I feel like I'm so close to solving the first version of this problem. I realized that I could use longestSharedSubstring method that we just finished to find the difference between the typed word and the original word, and I've been trying to use this method to calculate the number of edits it takes to get from the typed word to the words in the dictionary. I'm still not returning an array of the right length but I feel like I'm super close. |
| March 9  |   2pm-2:30pm    |                                                                                                                                                                                                                                                            I've continued to try to get my code to work using the longest substring between typed and the dictionary words. At this point I think I'll have to change the longestSharedSubstring method to work with the code, as the ordering of the letters in the shared substrings matters. |
| March 9  |   2:30pm-3pm    | I realized that it would be easier to alter the longestSharedSubstring method to just return the minimum number of edits necessary to make one word match another. I'm now basically going at this problem with a tabulation approach, and I'm running the tabulation method on every word in the dictionary to find the ones with the lowest number of edits needed to match the typed word. I haven't figured out how to make the tabulation method return the right number of edits quite yet, but I think I'm getting closer to solving it. |
| March 9  |  3:45pm-4:30pm  |              I've continued to try to edit my tabulation method to correctly return the number of edits required to get from one word to another. I realized that the first thing that each index should be attempted to be set to is it's upper-left diagonal index, as this would represent making both words ending on the upper left diagonal index 1 letter longer (if the current letters match, there's no need to add 1 to the original edit value). However, my code still doesn't work as intended, though I'm still making progress. |
| March 9  |   4:30pm-5pm    |                                                                                                        I realized that if the given letters didn't match then the current index could also potentially be set to the up-left diagonal index + 1, if it exists. I added this into my tabulation method and now I pass the small test case, have a different word in the 2nd index for the med test case, and return 1 too many words for the largest test case. I'll focus on that last error and try to eliminate the edge case that causes it. |
| March 9  |   5pm-5:15pm    |                                                                   I think I got my code to work. I realized that if there was a character match with a repeated character in the first row or column that it could lead to an edit that was unaccounted for, leading to the extra word that was added in the largest test case. I added in two if-statements to my code and now it passes the small test, and for the two larger tests it gets the first suggested word right but has a different word than the answer list later in the array. |
| March 10 |  9:40am-9:55am  |                                                                                                                                                               I thought about how I would cull the entire dictionary of words down into a smaller list of candidate words. I added in a statement to keep out all the words that would exceed the edit threshold based on length alone, however I'm not sure how else I'll keep out the less likely words. I also started working on a main method to run my code on the large dictionary file. |
| March 14 | 12:45pm-1:15pm  |                                                                                                                                                                                                                                           I used an LLM (Gemini) to figure out how to sort the words I returned alphabetically. I just made a new TreeMap from my dictionary HashMap, which then sorted them alphabetically automatically. I'll now try to figure out more ways to cull words before running my editDistance tabulation method. |
| March 14 |  1:15pm-1:25pm  |                                                                                                                                                                                                                                                                                                                                                                                                                      I spent a bit of time shortening my tabulation method that finds edit distance to make it simpler and more understandable. |
| March 18 | 11:05am-11:35am |                                                                                                                                                               With some help from Mr. Blick I got my main method to work and figured out how to run it continually in the console. I also realized that at first I could only run it once before restarting the console, so I altered my runTest() method to reset the values of the dict HashMap after every run. I also worked on the aesthetics of the print statements in my runner method. |
| March 18 | 11:35am-11:55am |                                                                                                                                                                                                                                                        I added in more nuance to my runner method by also using the longest shared subsequence to increase the similarity in the Strings I compare to typed with editDistance. I now use the longestSharedSubsequence() method and the length of the String to narrow down the words initially. |
| March 20 |  8:45am-9:15am  |                                                                                                                                                                    I talked with Beckett for a while and we tried to figure out simple ways to cut down the initial pool of words. One promising method we came up with was the idea of n-grams, which I think would be a cool way to cull the initial pool of dictionary words. I also played around with my initial edit threshold, and landed on 4 as the best option after trial and error. |
| March 20 |  9:15am-9:55am  |                                                                                                                                                                                                                                                                                                      I realized that I had to do more work on the time complexity and project description text files, so I started doing those and actually made a lot of progress. I finished a first draft of both and am getting pretty close to submitting. |
| March 21 |   2:20pm-3pm    |                                                                                                                                                                              I decided to take out the LCS check in my runTest() method, realising that it didn't end up making much of a difference in the final selected words. I continued to think through ways to cull down my initial word pool. While I know n-grams and tokenization could be a promising option, I feel like there could be a shorter but just as effective technique. |


To add a new row to the table, click into a cell and then hit shift-enter.